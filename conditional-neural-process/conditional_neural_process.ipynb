{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Neural Processes (CNP) for 1D regression.\n",
    "[Conditional Neural Processes](https://arxiv.org/pdf/1807.01613.pdf) (CNPs) were\n",
    "introduced as a continuation of\n",
    "[Generative Query Networks](https://deepmind.com/blog/neural-scene-representation-and-rendering/)\n",
    "(GQN) to extend its training regime to tasks beyond scene rendering, e.g. to\n",
    "regression and classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import numpy as np\n",
    "import torchsnooper\n",
    "import os\n",
    "import plotting_utils as plotting\n",
    "import data_generator as data\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../utilities/concept.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Neural Processes\n",
    "\n",
    "We can visualise a forward pass in a CNP as follows:\n",
    "\n",
    "<img src=\"https://bit.ly/2OFb6ZK\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "As shown in the diagram, CNPs take in pairs **(x, y)<sub>i</sub>** of context\n",
    "points, pass them through an **encoder** to obtain\n",
    "individual representations **r<sub>i</sub>** which are combined using an **aggregator**. The resulting representation **r**\n",
    "is then combined with the locations of the targets **x<sub>T</sub>** and passed\n",
    "through a **decoder** that returns a mean estimate\n",
    "of the **y** value at that target location together with a measure of the\n",
    "uncertainty over said prediction. Implementing CNPs therefore involves coding up\n",
    "the three main building blocks:\n",
    "\n",
    "*   Encoder\n",
    "*   Aggregator\n",
    "*   Decoder\n",
    "\n",
    "A more detailed description of these three parts is presented in the following\n",
    "sections alongside the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "\n",
    "The encoder **e** is shared between all the context points and consists of an\n",
    "MLP with a handful of layers. For this experiment four layers are enough, but we\n",
    "can still change the number and size of the layers when we build the graph later\n",
    "on via the variable **`encoder_output_sizes`**. Each of the context pairs **(x,\n",
    "y)<sub>i</sub>** results in an individual representation **r<sub>i</sub>** after\n",
    "encoding. These representations are then combined across context points to form\n",
    "a single representation **r** using the aggregator **a**.\n",
    "\n",
    "In this implementation we have included the aggregator **a** in the encoder as\n",
    "we are only taking the mean across all points. The representation **r** produced\n",
    "by the aggregator contains the information about the underlying unknown function\n",
    "**f** that is provided by all the context points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeterministicEncoder(nn.Module):\n",
    "    def __init__(self, output_sizes):\n",
    "        super(DeterministicEncoder, self).__init__()\n",
    "        self.linears = nn.ModuleList()\n",
    "        for i in range(len(output_sizes) - 1):\n",
    "            self.linears.append(nn.Linear(output_sizes[i], output_sizes[i + 1]))\n",
    "\n",
    "    def forward(self, context_x, context_y):\n",
    "        \"\"\"Encodes the inputs into one representation.\n",
    "\n",
    "        Args:\n",
    "        context_x: Tensor of size of batches x observations x m_ch. For this 1D regression\n",
    "          task this corresponds to the x-values.\n",
    "        context_y: Tensor of size bs x observations x d_ch. For this 1D regression\n",
    "          task this corresponds to the y-values.\n",
    "\n",
    "        Returns:\n",
    "            representation: The encoded representation averaged over all context \n",
    "            points.\n",
    "        \"\"\"\n",
    "\n",
    "        # Concatenate x and y along the filter axes\n",
    "        encoder_input = torch.cat((context_x, context_y), dim=-1)\n",
    "\n",
    "        # Get the shapes of the input and reshape to parallelise across observations\n",
    "        batch_size, num_context_points, _ = encoder_input.shape\n",
    "        hidden = encoder_input.view(batch_size * num_context_points, -1)\n",
    "        \n",
    "        # Pass through MLP\n",
    "        for i, linear in enumerate(self.linears[:-1]):\n",
    "            hidden = torch.relu(linear(hidden))\n",
    "        # Last layer without a ReLu\n",
    "        hidden = self.linears[-1](hidden)\n",
    "        # Bring back into original shape (# Flatten the output feature map into a 1D feature vector)\n",
    "        hidden = hidden.view(batch_size, num_context_points, -1)\n",
    "\n",
    "        # Aggregator: take the mean over all points\n",
    "        representation = hidden.mean(dim=1)\n",
    "        return representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "\n",
    "Once we have obtained our representation **r** we concatenate it with each of\n",
    "the targets **x<sub>t</sub>** and pass it through the decoder **d**. As with the\n",
    "encoder **e**, the decoder **d** is shared between all the target points and\n",
    "consists of a small MLP with layer sizes defined in **`decoder_output_sizes`**.\n",
    "The decoder outputs a mean **&mu;<sub>t</sub>** and a variance\n",
    "**&sigma;<sub>t</sub>** for each of the targets **x<sub>t</sub>**. To train our\n",
    "CNP we use the log likelihood of the ground truth value **y<sub>t</sub>** under\n",
    "a Gaussian parametrized by these predicted **&mu;<sub>t</sub>** and\n",
    "**&sigma;<sub>t</sub>**.\n",
    "\n",
    "In this implementation we clip the variance **&sigma;<sub>t</sub>** at 0.1 to\n",
    "avoid collapsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeterministicDecoder(nn.Module):\n",
    "    def __init__(self, output_sizes):\n",
    "        \"\"\"CNP decoder.\n",
    "        Args:\n",
    "            output_sizes: An iterable containing the output sizes of the decoder MLP.\n",
    "        \"\"\"\n",
    "        super(DeterministicDecoder, self).__init__()\n",
    "        self.linears = nn.ModuleList()\n",
    "        for i in range(len(output_sizes) - 1):\n",
    "            self.linears.append(nn.Linear(output_sizes[i], output_sizes[i + 1]))\n",
    "\n",
    "    def forward(self, representation, target_x):\n",
    "        \"\"\"Decodes the individual targets.\n",
    "\n",
    "        Args:\n",
    "            representation: The encoded representation of the context\n",
    "            target_x: The x locations for the target query\n",
    "\n",
    "        Returns:\n",
    "            dist: A multivariate Gaussian over the target points.\n",
    "            mu: The mean of the multivariate Gaussian.\n",
    "            sigma: The standard deviation of the multivariate Gaussian.   \n",
    "        \"\"\"\n",
    "\n",
    "        # Get the shapes of the input and reshape to parallelise across observations\n",
    "        batch_size, num_total_points, _ = target_x.shape\n",
    "        representation = representation.unsqueeze(1).repeat([1, num_total_points, 1])\n",
    "\n",
    "        # Concatenate the representation and the target_x\n",
    "        input = torch.cat((representation, target_x), dim=-1)\n",
    "        hidden = input.view(batch_size * num_total_points, -1)\n",
    "\n",
    "        # Pass through MLP\n",
    "        for i, linear in enumerate(self.linears[:-1]):\n",
    "            hidden = torch.relu(linear(hidden))\n",
    "        # Last layer without a ReLu\n",
    "        hidden = self.linears[-1](hidden)\n",
    "\n",
    "        # Bring back into original shape\n",
    "        hidden = hidden.view(batch_size, num_total_points, -1)\n",
    "\n",
    "        return torch.sigmoid(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Now that the main building blocks (encoder, aggregator and decoder) of the CNP\n",
    "are defined we can put everything together into one model. Fundamentally this\n",
    "model only needs to include two main methods: 1. A method that returns the log\n",
    "likelihood of the targets' ground truth values under the predicted\n",
    "distribution.This method will be called during training as our loss function. 2.\n",
    "Another method that returns the predicted mean and variance at the target\n",
    "locations in order to evaluate or query the CNP at test time. This second method\n",
    "needs to be defined separately as, unlike the method above, it should not depend\n",
    "on the ground truth target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeterministicModel(nn.Module):\n",
    "    def __init__(self, encoder_sizes, decoder_sizes):\n",
    "        super(DeterministicModel, self).__init__()\n",
    "        \"\"\"Initialises the model.\n",
    "\n",
    "        Args:\n",
    "            encoder_output_sizes: An iterable containing the sizes of hidden layers of\n",
    "                the encoder. The last one is the size of the representation r.\n",
    "            decoder_output_sizes: An iterable containing the sizes of hidden layers of\n",
    "                the decoder. The last element should correspond to the dimension of\n",
    "                the y * 2 (it encodes both mean and variance concatenated)\n",
    "        \"\"\"\n",
    "        self._encoder = DeterministicEncoder(encoder_sizes)\n",
    "        self._decoder = DeterministicDecoder(decoder_sizes)\n",
    "\n",
    "    def forward(self, query):\n",
    "        \"\"\"Returns the predicted mean and variance at the target points.\n",
    "\n",
    "        Args:\n",
    "            query: Array containing ((context_x, context_y), target_x) where:\n",
    "                context_x: Array of shape batch_size x num_context x 1 contains the \n",
    "                    x values of the context points.\n",
    "                context_y: Array of shape batch_size x num_context x 1 contains the \n",
    "                    y values of the context points.\n",
    "                target_x: Array of shape batch_size x num_target x 1 contains the\n",
    "                    x values of the target points.\n",
    "            target_y: The ground truth y values of the target y. An array of \n",
    "                shape batchsize x num_targets x 1.\n",
    "\n",
    "        Returns:\n",
    "            log_p: The log_probability of the target_y given the predicted\n",
    "            distribution.\n",
    "            mu: The mean of the predicted distribution.\n",
    "            sigma: The variance of the predicted distribution.\n",
    "        \"\"\"\n",
    "\n",
    "        (context_x, context_y), target_x = query\n",
    "        # Pass query through the encoder and the decoder\n",
    "\n",
    "        representation = self._encoder(context_x, context_y)\n",
    "        hidden = self._decoder(representation, target_x)\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Conditional Neural Processes\n",
    "\n",
    "Now that we have defined the dataset as well as our model and its components we\n",
    "can start building everything into the graph. Before we get started we need to\n",
    "set some variables:\n",
    "\n",
    "*   **`TRAINING_ITERATIONS`** - a scalar that describes the number of iterations\n",
    "    for training. At each iteration we will sample a new batch of functions from\n",
    "    the GP, pick some of the points on the curves as our context points **(x,\n",
    "    y)<sub>C</sub>** and some points as our target points **(x,\n",
    "    y)<sub>T</sub>**. We will predict the mean and variance at the target points\n",
    "    given the context and use the log likelihood of the ground truth targets as\n",
    "    our loss to update the model.\n",
    "*   **`MAX_CONTEXT_POINTS`** - a scalar that sets the maximum number of contest\n",
    "    points used during training. The number of context points will then be a\n",
    "    value between 3 and `MAX_CONTEXT_POINTS` that is sampled at random for every\n",
    "    iteration.\n",
    "*   **`PLOT_AFTER`** - a scalar that regulates how often we plot the\n",
    "    intermediate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_ITERATIONS = int(4000) # Total number of training points: training_iterations * batch_size * max_content_points\n",
    "#BATCH_SIZE = 100 # number of simulation configurations\n",
    "\n",
    "MAX_CONTEXT_POINTS = 1000 # 2000 # 4000\n",
    "MAX_TARGET_POINTS =  2000 # 4000 # 8000\n",
    "CONTEXT_IS_SUBSET = True\n",
    "BATCH_SIZE = 1\n",
    "CONFIG_WISE = False\n",
    "PLOT_AFTER = int(100)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# all available x config/ physics parameters are [\"radius\",\"thickness\",\"npanels\",\"theta\",\"length\",\"height\",\"z_offset\",\"volume\",\"nC_Ge77\",\"time_0[ms]\",\"x_0[m]\",\"y_0[m]\",\"z_0[m]\",\"px_0[m]\",\"py_0[m]\",\"pz_0[m]\",\"ekin_0[eV]\",\"edep_0[eV]\",\"time_t[ms]\",\"x_t[m]\",\"y_t[m]\",\"z_t[m]\",\"px_t[m]\",\"py_t[m]\",\"pz_t[m]\",\"ekin_t[eV]\",\"edep_t[eV]\",\"nsec\"]\n",
    "# Comment: if using data version v1.1 for training, \"radius\",\"thickness\",\"npanels\",\"theta\",\"length\" is probably necessary\n",
    "names_x=[\"radius\",\"thickness\",\"npanels\",\"theta\",\"length\",\"r_0[m]\",\"z_0[m]\",\"time_t[ms]\",\"r_t[m]\",\"z_t[m]\",\"L_t[m]\",\"ln(E0vsET)\",\"edep_t[eV]\",\"nsec\"]\n",
    "name_y ='total_nC_Ge77[cts]'\n",
    "x_size = len(names_x)\n",
    "if isinstance(name_y,str):\n",
    "    y_size = 1\n",
    "else:\n",
    "    y_size = len(name_y)\n",
    "\n",
    "RATIO_TESTING_VS_TRAINING = 1/40\n",
    "version=\"v1.2\"\n",
    "path_to_files=f\"../simulation/out/LF/{version}/tier2/\"\n",
    "path_out = f'./out/'\n",
    "f_out = f'{path_out}CNP_{version}_{TRAINING_ITERATIONS}_c{MAX_CONTEXT_POINTS}_t{MAX_TARGET_POINTS}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation methods used:\n",
    "\n",
    "<img src=\"../utilities/data_augmentation.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data augmentation parameters\n",
    "USE_DATA_AUGMENTATION = \"mixup\" #\"smote\" #False #\"mixup\"\n",
    "USE_BETA = [0.1,0.1] # uniform => None, beta => [a,b] U-shape [0.5,0.5] Uniform [1.,1.] falling [0.5,2] rising [2,0.5]\n",
    "SIGNAL_TO_BACKGROUND_RATIO = \"\" # \"_1to4\" # used for smote augmentation\n",
    "\n",
    "if USE_DATA_AUGMENTATION:\n",
    "    path_out = f'./out/{USE_DATA_AUGMENTATION}/'\n",
    "    f_out = f'CNP_{version}_{TRAINING_ITERATIONS}_c{MAX_CONTEXT_POINTS}_t{MAX_TARGET_POINTS}_{USE_DATA_AUGMENTATION}{SIGNAL_TO_BACKGROUND_RATIO}'\n",
    "    if USE_DATA_AUGMENTATION == \"mixup\":\n",
    "        path_to_files = f\"../simulation/out/LF/{version}/tier3/beta_{USE_BETA[0]}_{USE_BETA[1]}/\"\n",
    "        f_out = f'CNP_{version}_{TRAINING_ITERATIONS}_c{MAX_CONTEXT_POINTS}_t{MAX_TARGET_POINTS}_beta_{USE_BETA[0]}_{USE_BETA[1]}'\n",
    "    elif USE_DATA_AUGMENTATION == \"smote\" and CONFIG_WISE == True:\n",
    "        path_to_files = f\"../simulation/out/LF/{version}/tier3/smote{SIGNAL_TO_BACKGROUND_RATIO}/\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset\n",
    "dataset_train = data.DataGeneration(num_iterations=TRAINING_ITERATIONS, num_context_points=MAX_CONTEXT_POINTS, num_target_points=MAX_TARGET_POINTS, batch_size = BATCH_SIZE, config_wise=CONFIG_WISE, path_to_files=path_to_files,x_size=x_size,y_size=y_size, mode = \"training\", ratio_testing=RATIO_TESTING_VS_TRAINING,sig_bkg_ratio = SIGNAL_TO_BACKGROUND_RATIO, use_data_augmentation=USE_DATA_AUGMENTATION, names_x = names_x, name_y=name_y)\n",
    "TRAINING_ITERATIONS = dataset_train._num_iterations\n",
    "dataset_testing = data.DataGeneration(num_iterations=int(np.round(TRAINING_ITERATIONS/PLOT_AFTER))+5, num_context_points=MAX_CONTEXT_POINTS, num_target_points=MAX_TARGET_POINTS, batch_size = 1, config_wise=False, path_to_files=f\"../simulation/out/LF/{version}/tier2/\",x_size=x_size,y_size=y_size, mode = \"testing\",ratio_testing=RATIO_TESTING_VS_TRAINING, sig_bkg_ratio = SIGNAL_TO_BACKGROUND_RATIO, use_data_augmentation=\"None\", names_x = names_x, name_y=name_y)\n",
    "TRAINING_ITERATIONS = dataset_train._num_iterations if TRAINING_ITERATIONS > dataset_train._num_iterations else TRAINING_ITERATIONS\n",
    "PLOT_AFTER =  int(5 * np.ceil(np.ceil(TRAINING_ITERATIONS/(dataset_testing._num_iterations-2))/5)) if PLOT_AFTER < int(np.ceil(TRAINING_ITERATIONS/(dataset_testing._num_iterations-2))) else PLOT_AFTER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now add the model to the graph and finalise it by defining the train step\n",
    "and the initializer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d_x, d_in, representation_size, d_out = x_size , x_size+y_size, 32, y_size\n",
    "encoder_sizes = [d_in, 32, 64, 128, 128, 128, 64, 48, representation_size]\n",
    "decoder_sizes = [representation_size + d_x, 32, 64, 128, 128, 128, 64, 48, d_out]\n",
    "\n",
    "model = DeterministicModel(encoder_sizes, decoder_sizes)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "# \n",
    "\n",
    "bce = nn.BCELoss()\n",
    "#kldivloss = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "#cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "iter_test = 0\n",
    "fout = open(f'{path_out}{f_out}_training.txt', \"w\")\n",
    "\n",
    "with PdfPages(f'{path_out}{f_out}_training.pdf') as pdf:\n",
    "\n",
    "    for it in range(TRAINING_ITERATIONS):\n",
    "\n",
    "        # load data:\n",
    "        data_train = dataset_train.get_data(it, CONTEXT_IS_SUBSET)\n",
    "\n",
    "        target_y_cnp = model(data_train.query)\n",
    "        loss = bce(target_y_cnp,  data_train.target_y)\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform gradient descent to update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # reset gradient to 0 on all parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        target_y_cnp = target_y_cnp[0].detach().numpy()\n",
    "        if it % int(PLOT_AFTER/2) == 0:\n",
    "            print('{} Iteration: {}/{}, train loss: {}'.format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),it, TRAINING_ITERATIONS,loss))\n",
    "            fout.write('Iteration: {}/{}, train loss: {}\\n'.format(it, TRAINING_ITERATIONS,loss))\n",
    "        if it % PLOT_AFTER == 0 or it == int(TRAINING_ITERATIONS-1):\n",
    "            data_test = dataset_testing.get_data(iter_test, CONTEXT_IS_SUBSET)\n",
    "            target_y_cnp_testing = model(data_test.query)\n",
    "            test_loss = bce(target_y_cnp_testing,  data_test.target_y)\n",
    "            \n",
    "            print(\"{}, Iteration: {}, test loss: {}\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), it, test_loss))\n",
    "            fout.write(\"{}, Iteration: {}, test loss: {}\\n\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), it, test_loss))\n",
    "            if isinstance(name_y,str):\n",
    "                fig = plotting.plot(target_y_cnp, data_train.target_y[0].detach().numpy(), f'{loss:.2f}', target_y_cnp_testing[0].detach().numpy(), data_test.target_y[0].detach().numpy(), f'{test_loss:.2f}', it)\n",
    "            else:\n",
    "                for k in range(y_size):\n",
    "                    fig = plotting.plot(target_y_cnp[:,k], data_train.target_y[0].detach().numpy()[:,k], f'{loss:.2f}', target_y_cnp_testing[0].detach().numpy()[:,k], data_test.target_y[0].detach().numpy()[:,k], f'{test_loss:.2f}', it)\n",
    "            if it % PLOT_AFTER*5 == 0 or it == int(TRAINING_ITERATIONS-1):\n",
    "                pdf.savefig(fig)\n",
    "            \n",
    "            plt.show()\n",
    "            plt.figure().clear()\n",
    "            plt.close()\n",
    "            plt.cla()\n",
    "            plt.clf()\n",
    "            iter_test += 1\n",
    "fout.close()\n",
    "torch.save(model, path_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add further Trainings iterations\n",
    "ADDITIONAL_ITERATIONS = 0\n",
    "\n",
    "if ADDITIONAL_ITERATIONS > 0:\n",
    "    dataset_train = data.DataGeneration(num_iterations=TRAINING_ITERATIONS+ADDITIONAL_ITERATIONS, num_context_points=MAX_CONTEXT_POINTS, num_target_points=MAX_TARGET_POINTS, batch_size = BATCH_SIZE, config_wise=CONFIG_WISE, path_to_files=path_to_files,x_size=x_size,y_size=y_size, mode = \"training\", ratio_testing=RATIO_TESTING_VS_TRAINING,sig_bkg_ratio = SIGNAL_TO_BACKGROUND_RATIO, use_data_augmentation=USE_DATA_AUGMENTATION, names_x = names_x, name_y=name_y)\n",
    "    ADDITIONAL_ITERATIONS = dataset_train._num_iterations-TRAINING_ITERATIONS\n",
    "\n",
    "    fout = open(f'{path_out}{f_out}_training.txt', \"w\")\n",
    "\n",
    "    # create a PdfPages object\n",
    "    pdf = PdfPages(f'{path_out}{f_out}_training.pdf')\n",
    "\n",
    "    for it in range(TRAINING_ITERATIONS, TRAINING_ITERATIONS+ADDITIONAL_ITERATIONS):\n",
    "        # load data:\n",
    "        data_train = dataset_train.get_data(it, CONTEXT_IS_SUBSET)\n",
    "        # Get the predicted mean and variance at the target points for the testing set\n",
    "        log_prob, mu, _ = model(data_train.query, data_train.target_y)\n",
    "        \n",
    "        # Define the loss\n",
    "        loss = -log_prob.mean()\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform gradient descent to update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # reset gradient to 0 on all parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if max(mu[0].detach().numpy()) <= 1 and min(mu[0].detach().numpy()) >= 0:\n",
    "            loss_bce = bce(mu, data_train.target_y)\n",
    "        else:\n",
    "            loss_bce = -1.\n",
    "\n",
    "        mu=mu[0].detach().numpy()\n",
    "        if it % 100 == 0:\n",
    "            print('{} Iteration: {}/{}, train loss: {:.4f} (vs BCE {:.4f})'.format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),it, TRAINING_ITERATIONS+ADDITIONAL_ITERATIONS,loss, loss_bce))\n",
    "            fout.write('Iteration: {}/{}, train loss: {:.4f} (vs BCE {:.4f})\\n'.format(it, TRAINING_ITERATIONS+ADDITIONAL_ITERATIONS,loss, loss_bce))\n",
    "        \n",
    "        if it % PLOT_AFTER == 0 or it == int(TRAINING_ITERATIONS-1):\n",
    "            data_testing = dataset_testing.get_data(iter_testing, CONTEXT_IS_SUBSET)\n",
    "            log_prob_testing, mu_testing, _ = model(data_testing.query, data_testing.target_y)\n",
    "            # Define the loss\n",
    "            loss_testing = -log_prob_testing.mean()\n",
    "\n",
    "            if max(mu_testing[0].detach().numpy()) <= 1 and min(mu_testing[0].detach().numpy()) >= 0:\n",
    "                loss_bce_testing = bce(mu_testing,  data_testing.target_y)\n",
    "            else:\n",
    "                loss_bce_testing = -1.\n",
    "\n",
    "            mu_testing=mu_testing[0].detach().numpy()\n",
    "            print(\"{}, Iteration: {}, test loss: {:.4f} (vs BCE {:.4f})\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), it, loss_testing, loss_bce_testing))\n",
    "            fout.write(\"{}, Iteration: {}, test loss: {:.4f} (vs BCE {:.4f})\\n\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), it, loss_testing, loss_bce_testing))\n",
    "            if isinstance(name_y,str):\n",
    "                fig = plotting.plot(mu, data_train.target_y[0].detach().numpy(), f'{loss:.2f}', mu_testing, data_testing.target_y[0].detach().numpy(), f'{loss_testing:.2f}', it)\n",
    "            else:\n",
    "                for k in range(y_size):\n",
    "                    fig = plotting.plot(mu[:,k], data_train.target_y[0].detach().numpy()[:,k], f'{loss:.2f}', mu_testing[:,k], data_testing.target_y[0].detach().numpy()[:,k], f'{loss_testing:.2f}', it)\n",
    "            if it % PLOT_AFTER*5 == 0 or it == int(TRAINING_ITERATIONS+ADDITIONAL_ITERATIONS-1):\n",
    "                pdf.savefig(fig)\n",
    "                plt.show()\n",
    "                plt.clf()\n",
    "\n",
    "            iter_testing += 1\n",
    "    pdf.close()\n",
    "    fout.close()\n",
    "\n",
    "#torch.save(model, path_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torch.load(path_out)\n",
    "\n",
    "version=\"v1.2\"\n",
    "mode=\"LF\"\n",
    "filelist = data.get_all_files(f\"../simulation/out/{mode}/{version}/tier2/neutron\")\n",
    "num_total_points = 50000\n",
    "\n",
    "\n",
    "MAX_CONTEXT_POINTS_NEW = int(1/3 * num_total_points)\n",
    "MAX_TARGET_POINTS_NEW = 2 * (MAX_CONTEXT_POINTS_NEW)\n",
    "\n",
    "x = np.empty([0,5])\n",
    "sum_target_y = np.empty([0,1])\n",
    "mean_target_y_cnp = np.empty([0,1])\n",
    "\n",
    "hist_target_sig = hist_target_bkg = hist_pred_sig = hist_pred_bkg = np.zeros(100)\n",
    "fout = open(f'{path_out}{f_out}_training.txt', \"a\")\n",
    "\n",
    "pdf = PdfPages(f'{path_out}{f_out}_result.pdf')\n",
    "for i,file in enumerate(filelist):\n",
    "    path_to_files = file[:-4]\n",
    "    dataset_config = data.DataGeneration(num_iterations=1, num_context_points=MAX_CONTEXT_POINTS_NEW, num_target_points=MAX_TARGET_POINTS_NEW, batch_size = 1, use_data_augmentation=\"None\", path_to_files=path_to_files,x_size=x_size,y_size=y_size, mode = \"config\", ratio_testing=0.,names_x=names_x, name_y=name_y)\n",
    "    data_config = dataset_config.get_data(0, CONTEXT_IS_SUBSET)\n",
    "    \n",
    "    target_y_cnp_config = model(data_config.query, data_config.target_y)\n",
    "    loss_config = bce(target_y_cnp_config,  data_train.target_y)\n",
    "\n",
    "    target_y_cnp_config = target_y_cnp_config[0].detach().numpy()\n",
    "    target_y = data_config.target_y[0].detach().numpy()\n",
    "    df = pd.read_csv(file, index_col=0)\n",
    "    tmp = df[[\"radius\",\"thickness\",\"npanels\",\"theta\",\"length\"]].to_numpy()\n",
    "    x         = np.append(x,[df[[\"radius\",\"thickness\",\"npanels\",\"theta\",\"length\"]].to_numpy()[0]],axis=0)\n",
    "    #x         = np.append(x,[data_config.query[1][0][0][-5:].numpy()],axis=0)\n",
    "\n",
    "    sum_target_y_tmp = np.array([np.sum(target_y)])\n",
    "    sum_target_y    = np.append(sum_target_y, [sum_target_y_tmp], axis=0)\n",
    "    mean_tmp = np.array([np.mean(target_y_cnp_config)])\n",
    "    mean_target_y_cnp = np.append(mean_target_y_cnp, [mean_tmp], axis=0)\n",
    "\n",
    "    hist_target_sig, hist_target_bkg, hist_pred_sig, hist_pred_bkg = plotting.sum_hist(target_y_cnp_config, target_y, hist_target_sig, hist_target_bkg, hist_pred_sig, hist_pred_bkg)\n",
    "    print(\"{}/{} {}, {}, radius: {} cm, test loss: {}\".format(i,len(filelist),datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), mode,x[-1,0], loss_config))\n",
    "    fout.write(\"{}, Iteration: {}, test loss: {}\\n\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), it, loss_config))\n",
    "\n",
    "    fig = plotting.plot_result_configwise(target_y_cnp_config, target_y, f'{loss_config:.2f}', x[-1])\n",
    "    pdf.savefig(fig)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "        \n",
    "fig1 = plotting.plot_result_summed(hist_target_sig, hist_target_bkg, hist_pred_sig, hist_pred_bkg)\n",
    "pdf.savefig(fig1)\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "fig2, ax = plt.subplots(ncols=2, figsize=(12, 4))\n",
    "ax[0].plot(x[:,0],mean_target_y_cnp,'o')\n",
    "ax[0].set_title('Conditional Neutral Process', fontsize=10)\n",
    "ax[0].set_xlabel('radius [cm]')\n",
    "#ax[0].set_ylim(0.0,0.15)\n",
    "ax[1].plot(x[:,0],sum_target_y,'o')\n",
    "ax[1].set_title('Simulation', fontsize=10)\n",
    "ax[1].set_xlabel('radius [cm]')\n",
    "pdf.savefig(fig2)\n",
    "plt.show()\n",
    "plt.clf()\n",
    "pdf.close()\n",
    "    \n",
    "fout.close()\n",
    "\n",
    "df = pd.DataFrame(x, columns=[\"Radius[cm]\",\"Thickness[cm]\",\"NPanels\",\"Theta[deg]\",\"Length[cm]\"])\n",
    "df['Ge-77[nevents]'] = sum_target_y\n",
    "df['Ge-77_CNP[nevents]'] = mean_target_y_cnp\n",
    "df=df.round(decimals=4)\n",
    "df.to_csv(f'{path_out}Ge77_rates_CNP_{version}.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
